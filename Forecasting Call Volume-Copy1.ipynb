{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Call Volume\n",
    "\n",
    "Data comes from Data.World's call center data. The file Call_Data.csv is pulled in. Additionally, a SQL query (run in the Data.World environment) of the data is also pulled. \n",
    "\n",
    "`select CAST(call_date as DATE), SUM(calls) from call_data\n",
    "group by CAST(call_date as DATE)\n",
    "order by CAST(call_date as DATE)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_df = pd.read_csv('Call_Data.csv')\n",
    "\n",
    "call_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_df[['CALLS', 'HANDLE_TIME', 'CALL_REGEN','CALLS_WITH_OFFER', 'CALLS_WITH_ACCEPT', 'CALLS_OFFER_APPLIED',\n",
    "       'TRANSFERS']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('call-center-test-data-QueryResult.csv')\n",
    "\n",
    "ts_df.rename(columns = {'call_date':'date', 'sum':'call_v'}, inplace = True)\n",
    "ts_df['date'] = pd.to_datetime(ts_df['date'])\n",
    "ts_df = ts_df.set_index('date')\n",
    "ts_df.reset_index(inplace=True)\n",
    "\n",
    "ts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA of Time Series Data (Daily Freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min = ts_df['date'].min()\n",
    "date_max = ts_df['date'].max()\n",
    "print('The data ranges from {} to {}'.format(date_min, date_max))\n",
    "\n",
    "obs = len(ts_df['date'])\n",
    "print('There are {} observations'.format(obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have more than 50 observations...shy of 100 plus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mod = ts_df\n",
    "df_mod['day'] = ts_df['date'].dt.day_name()\n",
    "df_mod['week'] = ts_df['date'].dt.week\n",
    "\n",
    "df_mod.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_freq = df_mod.groupby(['day']).sum()\n",
    "\n",
    "day_freq.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_freq = df_mod.groupby(['week']).sum()\n",
    "\n",
    "week_freq.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ts_df['call_v'], density=False, bins=20)\n",
    "plt.ylabel('Call Volumes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "# ax1 = fig.add_subplot(2, 2, 1)\n",
    "# ax2 = fig.add_subplot(2, 2, 2)\n",
    "# ax3 = fig.add_subplot(2, 2, 3)\n",
    "# ax4 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "# ax1.plot(ts_df['date'], ts_df['call_v'])\n",
    "# fig.xlabel('Date') \n",
    "# # ax1.ylabel('Call Volume') \n",
    "# # ax1.title('Daily Call Volume (June 1, 2017 to August 31, 2017)') \n",
    "\n",
    "# ax2.plot(ts_df['date'], np.log(ts_df['call_v']))\n",
    "# # ax2.xlabel('Date') \n",
    "# # ax2.ylabel('Call Volume') \n",
    "# # ax2.title('Daily Call Volume (June 1, 2017 to August 31, 2017)') \n",
    "\n",
    "# ax3.plot(ts_df['date'][1:], np.diff((ts_df['call_v'])))\n",
    "# # ax3.xlabel('Date') \n",
    "# # ax3.ylabel('Call Volume') \n",
    "# # ax3.title('Daily Call Volume (June 1, 2017 to August 31, 2017)') \n",
    "\n",
    "# ax4.plot(ts_df['date'][1:], np.diff(np.log(ts_df['call_v'])))\n",
    "# # ax4.xlabel('Date') \n",
    "# # ax4.ylabel('Call Volume') \n",
    "# # ax4.title('Daily Call Volume (June 1, 2017 to August 31, 2017)') \n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.plot(ts_df['date'], ts_df['call_v'])\n",
    "plt.xlabel('Date') \n",
    "plt.ylabel('Call Volume') \n",
    "plt.title('Daily Call Volume (June 1, 2017 to August 31, 2017)') \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.plot(ts_df['date'], np.log(ts_df['call_v']))\n",
    "plt.xlabel('Date') \n",
    "plt.ylabel('Call Volume') \n",
    "plt.title('Daily Call Volume (June 1, 2017 to August 31, 2017)') \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.plot(ts_df['date'][1:], np.diff((ts_df['call_v'])))\n",
    "plt.xlabel('Date') \n",
    "plt.ylabel('Call Volume') \n",
    "plt.title('Daily Call Volume (June 1, 2017 to August 31, 2017)') \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.plot(ts_df['date'][1:], np.diff(np.log(ts_df['call_v'])))\n",
    "plt.xlabel('Date') \n",
    "plt.ylabel('Call Volume') \n",
    "plt.title('Daily Call Volume (June 1, 2017 to August 31, 2017)') \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 7\n",
    "matplotlib.rcParams['ytick.labelsize'] = 7\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "ax1.plot(ts_df['date'], ts_df['call_v'])\n",
    "ax1.set_title('Daily Call Volume (Levels)') \n",
    "\n",
    "ax2.plot(ts_df['date'], np.log(ts_df['call_v']))\n",
    "ax2.set_title('Daily Call Volume (Natural Log)') \n",
    "\n",
    "ax3.plot(ts_df['date'][1:], np.diff((ts_df['call_v']))) \n",
    "ax3.set_title('Daily Call Volume (First Difference)') \n",
    "\n",
    "ax4.plot(ts_df['date'][1:], np.diff(np.log(ts_df['call_v'])))\n",
    "ax4.set_title('Daily Call Volume (Log-Differenced)') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in levels doesn't look terrible, but the first difference looks like a good bet. We can check stationarity w/ ADF and KPSS tests below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more accurate test of our ability to forecast call volume, we can split the data into test and train.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df['date'] = pd.to_datetime(ts_df['date'])\n",
    "ts_df = ts_df.set_index('date')\n",
    "ts_df.reset_index(inplace=True)\n",
    "ts_df.drop('day',1, inplace = True)\n",
    "\n",
    "ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = ts_df[:int(0.7*(len(ts_df['call_v'])))]\n",
    "test = ts_df[int(0.7*(len(ts_df['call_v']))):]\n",
    "\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from Analytics Vidha\n",
    "# Link: https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(timeseries):\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    # Picks the best AIC (Akaike information criterion)\n",
    "    dftest = adfuller(timeseries, autolag= 'AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "       dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "\n",
    "adf_test(train['call_v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-value greater than 0.1, indicates that the series is non-stationary in levels. Let's test it on the first-differenced series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(np.diff(train['call_v']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can auto generate an ARIMA, both R and Python have nice auto-arima functions. They can save us time and if we don't like the results we can always build them by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pmdarima  import auto_arima\n",
    "\n",
    "arima_model = auto_arima(train['call_v'], trace = True, start_p = 0, d =0, start_q = 0,\n",
    "                  max_p = 10, max_q = 10, m = 7, seasonal = True,\n",
    "                  stepwise = True, suppress_warnings = True)\n",
    "\n",
    "arima_model.fit(train['call_v'])\n",
    "\n",
    "arima_forecast = arima_model.predict(n_periods=len(test['call_v']))\n",
    "sarima_forecast_df = pd.DataFrame(forecast,index = test['call_v'].index,columns=['Prediction'])\n",
    "\n",
    "#plot the predictions for validation set\n",
    "plt.plot(train['call_v'], label='Train')\n",
    "plt.plot(test['call_v'], label='Valid')\n",
    "plt.plot(sarima_forecast_df, label='Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model.resid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arima_model.resid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(test['call_v'], arima_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbats import TBATS, BATS\n",
    "\n",
    "estimator = TBATS(seasonal_periods = (7, 4))\n",
    "tbats_model = estimator.fit(train['call_v'])\n",
    "\n",
    "tbats_forecast = tbats_model.forecast(steps = len(test['call_v']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tbats_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tbats_model.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tbats_forecast_df = test\n",
    "\n",
    "tbats_forecast_df['TBATS Forecast'] = tbats_forecast\n",
    "\n",
    "tbats_forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train['call_v'], label='Train')\n",
    "plt.plot(test['call_v'], label='Test')\n",
    "plt.plot(tbats_forecast_df['TBATS Forecast'], label = 'Forecast')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(test['call_v'], tbats_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
